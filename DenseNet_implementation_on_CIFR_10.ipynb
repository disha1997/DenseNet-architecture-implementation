{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK3alCdFflQX"
      },
      "source": [
        "### CNN on CIFR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHCYMwwXflQd"
      },
      "source": [
        "1.  You cannot use DropOut layers.\n",
        "2.  You MUST use Image Augmentation Techniques.\n",
        "3.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
        "4.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
        "5.  You cannot use test images for training the model.\n",
        "6.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
        "7.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
        "8. You cannot have more than 1 Million parameters in total\n",
        "9. You can use any optimization algorithm you need. \n",
        "10. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLVcyNYKflQi"
      },
      "source": [
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "rmck-mMq_rcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "l = 12\n",
        "num_filter = 58\n",
        "compression = 1\n",
        "dropout_rate = 0.2"
      ],
      "metadata": {
        "id": "tJMDrVI1AHTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ],
      "metadata": {
        "id": "cRQpbJbzATT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABUNGHXkAfJx",
        "outputId": "cdf7c7be-0d26-42ca-e785-fa47e1a561e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#Image data augmentation is typically only applied to the training dataset, and not to the validation or test dataset\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0,width_shift_range=0.2,height_shift_range=0.2,horizontal_flip=True, \n",
        "                             shear_range=0.2,zoom_range=0.2,validation_split=0.2)\n",
        "train_iterator = datagen.flow(X_train, y_train)\n",
        "\n",
        "#Image pixel scaling must be performed consistently across all datasets that interact with the model.\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "test_iterator = datagen.flow(X_test, y_test)"
      ],
      "metadata": {
        "id": "kbx9gJchN9Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (5,5), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "# Transition Block\n",
        "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (5,5), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "# Output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output"
      ],
      "metadata": {
        "id": "qriJKcR8Arcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0\n",
        "l = 10\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "metadata": {
        "id": "8DRsljadImul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwIhmC6iJN53",
        "outputId": "ec76e976-19eb-43b6-93d9-a1164400a5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 32, 32, 12)   324         ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 32, 32, 12)  48          ['conv2d_132[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_132 (Activation)    (None, 32, 32, 12)   0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 32, 32, 12)   3600        ['activation_132[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_120 (Concatenate)  (None, 32, 32, 24)   0           ['conv2d_132[0][0]',             \n",
            "                                                                  'conv2d_133[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 32, 32, 24)  96          ['concatenate_120[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_133 (Activation)    (None, 32, 32, 24)   0           ['batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 32, 32, 12)   7200        ['activation_133[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_121 (Concatenate)  (None, 32, 32, 36)   0           ['concatenate_120[0][0]',        \n",
            "                                                                  'conv2d_134[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 32, 32, 36)  144         ['concatenate_121[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_134 (Activation)    (None, 32, 32, 36)   0           ['batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 32, 32, 12)   10800       ['activation_134[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_122 (Concatenate)  (None, 32, 32, 48)   0           ['concatenate_121[0][0]',        \n",
            "                                                                  'conv2d_135[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 32, 32, 48)  192         ['concatenate_122[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_135 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 32, 32, 12)   14400       ['activation_135[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_123 (Concatenate)  (None, 32, 32, 60)   0           ['concatenate_122[0][0]',        \n",
            "                                                                  'conv2d_136[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 32, 32, 60)  240         ['concatenate_123[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_136 (Activation)    (None, 32, 32, 60)   0           ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 32, 32, 12)   18000       ['activation_136[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_124 (Concatenate)  (None, 32, 32, 72)   0           ['concatenate_123[0][0]',        \n",
            "                                                                  'conv2d_137[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 32, 32, 72)  288         ['concatenate_124[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_137 (Activation)    (None, 32, 32, 72)   0           ['batch_normalization_137[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)            (None, 32, 32, 12)   21600       ['activation_137[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_125 (Concatenate)  (None, 32, 32, 84)   0           ['concatenate_124[0][0]',        \n",
            "                                                                  'conv2d_138[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 32, 32, 84)  336         ['concatenate_125[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_138 (Activation)    (None, 32, 32, 84)   0           ['batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)            (None, 32, 32, 12)   25200       ['activation_138[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_126 (Concatenate)  (None, 32, 32, 96)   0           ['concatenate_125[0][0]',        \n",
            "                                                                  'conv2d_139[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 32, 32, 96)  384         ['concatenate_126[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_139 (Activation)    (None, 32, 32, 96)   0           ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)            (None, 32, 32, 12)   28800       ['activation_139[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_127 (Concatenate)  (None, 32, 32, 108)  0           ['concatenate_126[0][0]',        \n",
            "                                                                  'conv2d_140[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 32, 32, 108)  432        ['concatenate_127[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_140 (Activation)    (None, 32, 32, 108)  0           ['batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)            (None, 32, 32, 12)   32400       ['activation_140[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_128 (Concatenate)  (None, 32, 32, 120)  0           ['concatenate_127[0][0]',        \n",
            "                                                                  'conv2d_141[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 32, 32, 120)  480        ['concatenate_128[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_141 (Activation)    (None, 32, 32, 120)  0           ['batch_normalization_141[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)            (None, 32, 32, 12)   36000       ['activation_141[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_129 (Concatenate)  (None, 32, 32, 132)  0           ['concatenate_128[0][0]',        \n",
            "                                                                  'conv2d_142[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 32, 32, 132)  528        ['concatenate_129[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_142 (Activation)    (None, 32, 32, 132)  0           ['batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)            (None, 32, 32, 12)   39600       ['activation_142[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_12 (AverageP  (None, 16, 16, 12)  0           ['conv2d_143[0][0]']             \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 16, 16, 12)  48          ['average_pooling2d_12[0][0]']   \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_143 (Activation)    (None, 16, 16, 12)   0           ['batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)            (None, 16, 16, 12)   3600        ['activation_143[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_130 (Concatenate)  (None, 16, 16, 24)   0           ['average_pooling2d_12[0][0]',   \n",
            "                                                                  'conv2d_144[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 16, 16, 24)  96          ['concatenate_130[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_144 (Activation)    (None, 16, 16, 24)   0           ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)            (None, 16, 16, 12)   7200        ['activation_144[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_131 (Concatenate)  (None, 16, 16, 36)   0           ['concatenate_130[0][0]',        \n",
            "                                                                  'conv2d_145[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 16, 16, 36)  144         ['concatenate_131[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_145 (Activation)    (None, 16, 16, 36)   0           ['batch_normalization_145[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)            (None, 16, 16, 12)   10800       ['activation_145[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_132 (Concatenate)  (None, 16, 16, 48)   0           ['concatenate_131[0][0]',        \n",
            "                                                                  'conv2d_146[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 16, 16, 48)  192         ['concatenate_132[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_146 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)            (None, 16, 16, 12)   14400       ['activation_146[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_133 (Concatenate)  (None, 16, 16, 60)   0           ['concatenate_132[0][0]',        \n",
            "                                                                  'conv2d_147[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_147 (Batch  (None, 16, 16, 60)  240         ['concatenate_133[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_147 (Activation)    (None, 16, 16, 60)   0           ['batch_normalization_147[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)            (None, 16, 16, 12)   18000       ['activation_147[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_134 (Concatenate)  (None, 16, 16, 72)   0           ['concatenate_133[0][0]',        \n",
            "                                                                  'conv2d_148[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_148 (Batch  (None, 16, 16, 72)  288         ['concatenate_134[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_148 (Activation)    (None, 16, 16, 72)   0           ['batch_normalization_148[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)            (None, 16, 16, 12)   21600       ['activation_148[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_135 (Concatenate)  (None, 16, 16, 84)   0           ['concatenate_134[0][0]',        \n",
            "                                                                  'conv2d_149[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_149 (Batch  (None, 16, 16, 84)  336         ['concatenate_135[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_149 (Activation)    (None, 16, 16, 84)   0           ['batch_normalization_149[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)            (None, 16, 16, 12)   25200       ['activation_149[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_136 (Concatenate)  (None, 16, 16, 96)   0           ['concatenate_135[0][0]',        \n",
            "                                                                  'conv2d_150[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_150 (Batch  (None, 16, 16, 96)  384         ['concatenate_136[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_150 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_150[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)            (None, 16, 16, 12)   28800       ['activation_150[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_137 (Concatenate)  (None, 16, 16, 108)  0           ['concatenate_136[0][0]',        \n",
            "                                                                  'conv2d_151[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_151 (Batch  (None, 16, 16, 108)  432        ['concatenate_137[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_151 (Activation)    (None, 16, 16, 108)  0           ['batch_normalization_151[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 16, 16, 12)   32400       ['activation_151[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_138 (Concatenate)  (None, 16, 16, 120)  0           ['concatenate_137[0][0]',        \n",
            "                                                                  'conv2d_152[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_152 (Batch  (None, 16, 16, 120)  480        ['concatenate_138[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_152 (Activation)    (None, 16, 16, 120)  0           ['batch_normalization_152[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 16, 16, 12)   36000       ['activation_152[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_139 (Concatenate)  (None, 16, 16, 132)  0           ['concatenate_138[0][0]',        \n",
            "                                                                  'conv2d_153[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_153 (Batch  (None, 16, 16, 132)  528        ['concatenate_139[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_153 (Activation)    (None, 16, 16, 132)  0           ['batch_normalization_153[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 16, 16, 12)   39600       ['activation_153[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_13 (AverageP  (None, 8, 8, 12)    0           ['conv2d_154[0][0]']             \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " batch_normalization_154 (Batch  (None, 8, 8, 12)    48          ['average_pooling2d_13[0][0]']   \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_154 (Activation)    (None, 8, 8, 12)     0           ['batch_normalization_154[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 8, 8, 12)     3600        ['activation_154[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_140 (Concatenate)  (None, 8, 8, 24)     0           ['average_pooling2d_13[0][0]',   \n",
            "                                                                  'conv2d_155[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_155 (Batch  (None, 8, 8, 24)    96          ['concatenate_140[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_155 (Activation)    (None, 8, 8, 24)     0           ['batch_normalization_155[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 8, 8, 12)     7200        ['activation_155[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_141 (Concatenate)  (None, 8, 8, 36)     0           ['concatenate_140[0][0]',        \n",
            "                                                                  'conv2d_156[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_156 (Batch  (None, 8, 8, 36)    144         ['concatenate_141[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_156 (Activation)    (None, 8, 8, 36)     0           ['batch_normalization_156[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 8, 8, 12)     10800       ['activation_156[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_142 (Concatenate)  (None, 8, 8, 48)     0           ['concatenate_141[0][0]',        \n",
            "                                                                  'conv2d_157[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_157 (Batch  (None, 8, 8, 48)    192         ['concatenate_142[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_157 (Activation)    (None, 8, 8, 48)     0           ['batch_normalization_157[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 8, 8, 12)     14400       ['activation_157[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_143 (Concatenate)  (None, 8, 8, 60)     0           ['concatenate_142[0][0]',        \n",
            "                                                                  'conv2d_158[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_158 (Batch  (None, 8, 8, 60)    240         ['concatenate_143[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_158 (Activation)    (None, 8, 8, 60)     0           ['batch_normalization_158[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 8, 8, 12)     18000       ['activation_158[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_144 (Concatenate)  (None, 8, 8, 72)     0           ['concatenate_143[0][0]',        \n",
            "                                                                  'conv2d_159[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_159 (Batch  (None, 8, 8, 72)    288         ['concatenate_144[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 8, 8, 72)     0           ['batch_normalization_159[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 8, 8, 12)     21600       ['activation_159[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_145 (Concatenate)  (None, 8, 8, 84)     0           ['concatenate_144[0][0]',        \n",
            "                                                                  'conv2d_160[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 8, 8, 84)    336         ['concatenate_145[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 8, 8, 84)     0           ['batch_normalization_160[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 8, 8, 12)     25200       ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_146 (Concatenate)  (None, 8, 8, 96)     0           ['concatenate_145[0][0]',        \n",
            "                                                                  'conv2d_161[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 8, 8, 96)    384         ['concatenate_146[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 8, 8, 96)     0           ['batch_normalization_161[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)            (None, 8, 8, 12)     28800       ['activation_161[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_147 (Concatenate)  (None, 8, 8, 108)    0           ['concatenate_146[0][0]',        \n",
            "                                                                  'conv2d_162[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (None, 8, 8, 108)   432         ['concatenate_147[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 8, 8, 108)    0           ['batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_163 (Conv2D)            (None, 8, 8, 12)     32400       ['activation_162[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_148 (Concatenate)  (None, 8, 8, 120)    0           ['concatenate_147[0][0]',        \n",
            "                                                                  'conv2d_163[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (None, 8, 8, 120)   480         ['concatenate_148[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 8, 8, 120)    0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)            (None, 8, 8, 12)     36000       ['activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_149 (Concatenate)  (None, 8, 8, 132)    0           ['concatenate_148[0][0]',        \n",
            "                                                                  'conv2d_164[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_164 (Batch  (None, 8, 8, 132)   528         ['concatenate_149[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_164 (Activation)    (None, 8, 8, 132)    0           ['batch_normalization_164[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)            (None, 8, 8, 12)     39600       ['activation_164[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_14 (AverageP  (None, 4, 4, 12)    0           ['conv2d_165[0][0]']             \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " batch_normalization_165 (Batch  (None, 4, 4, 12)    48          ['average_pooling2d_14[0][0]']   \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_165 (Activation)    (None, 4, 4, 12)     0           ['batch_normalization_165[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_166 (Conv2D)            (None, 4, 4, 12)     3600        ['activation_165[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_150 (Concatenate)  (None, 4, 4, 24)     0           ['average_pooling2d_14[0][0]',   \n",
            "                                                                  'conv2d_166[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_166 (Batch  (None, 4, 4, 24)    96          ['concatenate_150[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_166 (Activation)    (None, 4, 4, 24)     0           ['batch_normalization_166[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_167 (Conv2D)            (None, 4, 4, 12)     7200        ['activation_166[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_151 (Concatenate)  (None, 4, 4, 36)     0           ['concatenate_150[0][0]',        \n",
            "                                                                  'conv2d_167[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_167 (Batch  (None, 4, 4, 36)    144         ['concatenate_151[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_167 (Activation)    (None, 4, 4, 36)     0           ['batch_normalization_167[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_168 (Conv2D)            (None, 4, 4, 12)     10800       ['activation_167[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_152 (Concatenate)  (None, 4, 4, 48)     0           ['concatenate_151[0][0]',        \n",
            "                                                                  'conv2d_168[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_168 (Batch  (None, 4, 4, 48)    192         ['concatenate_152[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_168 (Activation)    (None, 4, 4, 48)     0           ['batch_normalization_168[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)            (None, 4, 4, 12)     14400       ['activation_168[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_153 (Concatenate)  (None, 4, 4, 60)     0           ['concatenate_152[0][0]',        \n",
            "                                                                  'conv2d_169[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_169 (Batch  (None, 4, 4, 60)    240         ['concatenate_153[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_169 (Activation)    (None, 4, 4, 60)     0           ['batch_normalization_169[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)            (None, 4, 4, 12)     18000       ['activation_169[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_154 (Concatenate)  (None, 4, 4, 72)     0           ['concatenate_153[0][0]',        \n",
            "                                                                  'conv2d_170[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_170 (Batch  (None, 4, 4, 72)    288         ['concatenate_154[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_170 (Activation)    (None, 4, 4, 72)     0           ['batch_normalization_170[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_171 (Conv2D)            (None, 4, 4, 12)     21600       ['activation_170[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_155 (Concatenate)  (None, 4, 4, 84)     0           ['concatenate_154[0][0]',        \n",
            "                                                                  'conv2d_171[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_171 (Batch  (None, 4, 4, 84)    336         ['concatenate_155[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_171 (Activation)    (None, 4, 4, 84)     0           ['batch_normalization_171[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_172 (Conv2D)            (None, 4, 4, 12)     25200       ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_156 (Concatenate)  (None, 4, 4, 96)     0           ['concatenate_155[0][0]',        \n",
            "                                                                  'conv2d_172[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_172 (Batch  (None, 4, 4, 96)    384         ['concatenate_156[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_172 (Activation)    (None, 4, 4, 96)     0           ['batch_normalization_172[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_173 (Conv2D)            (None, 4, 4, 12)     28800       ['activation_172[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_157 (Concatenate)  (None, 4, 4, 108)    0           ['concatenate_156[0][0]',        \n",
            "                                                                  'conv2d_173[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_173 (Batch  (None, 4, 4, 108)   432         ['concatenate_157[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_173 (Activation)    (None, 4, 4, 108)    0           ['batch_normalization_173[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)            (None, 4, 4, 12)     32400       ['activation_173[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_158 (Concatenate)  (None, 4, 4, 120)    0           ['concatenate_157[0][0]',        \n",
            "                                                                  'conv2d_174[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_174 (Batch  (None, 4, 4, 120)   480         ['concatenate_158[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_174 (Activation)    (None, 4, 4, 120)    0           ['batch_normalization_174[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)            (None, 4, 4, 12)     36000       ['activation_174[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_159 (Concatenate)  (None, 4, 4, 132)    0           ['concatenate_158[0][0]',        \n",
            "                                                                  'conv2d_175[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_175 (Batch  (None, 4, 4, 132)   528         ['concatenate_159[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_175 (Activation)    (None, 4, 4, 132)    0           ['batch_normalization_175[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_15 (AverageP  (None, 2, 2, 132)   0           ['activation_175[0][0]']         \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 528)          0           ['average_pooling2d_15[0][0]']   \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 10)           5290        ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 929,086\n",
            "Trainable params: 922,750\n",
            "Non-trainable params: 6,336\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(model.layers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i7bZX7EJRV3",
        "outputId": "31d671f6-5284-4289-9c2d-f30ff411a56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "52mgOEQpLy8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Callback(tf.keras.callbacks.Callback):\n",
        "\tdef on_epoch_end(self, epoch, logs=None):\n",
        "\t\tif(logs.get('accuracy') > 0.90):\n",
        "\t\t\tself.model.stop_training = True"
      ],
      "metadata": {
        "id": "OdoWuF1rHcmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = Callback()"
      ],
      "metadata": {
        "id": "bt_UfkngHe7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_iterator, steps_per_epoch=(len(train_iterator)//2), epochs=100,callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFvnTLGmLy1A",
        "outputId": "e9c9e7d8-5a2d-475e-bc39-6f8e6cb7b2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.3995 - accuracy: 0.4925\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.2594 - accuracy: 0.5413\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.1418 - accuracy: 0.5940\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.0633 - accuracy: 0.6231\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.9775 - accuracy: 0.6553\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.9250 - accuracy: 0.6749\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.8538 - accuracy: 0.6996\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.8193 - accuracy: 0.7115\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.7847 - accuracy: 0.7240\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.7543 - accuracy: 0.7359\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.7232 - accuracy: 0.7462\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.6954 - accuracy: 0.7580\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.6773 - accuracy: 0.7634\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.6556 - accuracy: 0.7701\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.6394 - accuracy: 0.7772\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.6093 - accuracy: 0.7887\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.5974 - accuracy: 0.7930\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.5803 - accuracy: 0.7987\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.5748 - accuracy: 0.8032\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5656 - accuracy: 0.8044\n",
            "Epoch 21/100\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5435 - accuracy: 0.8131\n",
            "Epoch 22/100\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5249 - accuracy: 0.8187\n",
            "Epoch 23/100\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5243 - accuracy: 0.8168\n",
            "Epoch 24/100\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.5090 - accuracy: 0.8214\n",
            "Epoch 25/100\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.5043 - accuracy: 0.8270\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4922 - accuracy: 0.8290\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4871 - accuracy: 0.8335\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4803 - accuracy: 0.8322\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4749 - accuracy: 0.8361\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4503 - accuracy: 0.8434\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4509 - accuracy: 0.8425\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4423 - accuracy: 0.8477\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4361 - accuracy: 0.8516\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4391 - accuracy: 0.8494\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.4199 - accuracy: 0.8550\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.4244 - accuracy: 0.8539\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.4121 - accuracy: 0.8554\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4101 - accuracy: 0.8585\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4042 - accuracy: 0.8589\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4011 - accuracy: 0.8625\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.3802 - accuracy: 0.8666\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.3845 - accuracy: 0.8668\n",
            "Epoch 43/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.3784 - accuracy: 0.8704\n",
            "Epoch 44/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.3762 - accuracy: 0.8690\n",
            "Epoch 45/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3808 - accuracy: 0.8675\n",
            "Epoch 46/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.3779 - accuracy: 0.8688\n",
            "Epoch 47/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3577 - accuracy: 0.8749\n",
            "Epoch 48/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.3644 - accuracy: 0.8748\n",
            "Epoch 49/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3622 - accuracy: 0.8731\n",
            "Epoch 50/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3493 - accuracy: 0.8782\n",
            "Epoch 51/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3433 - accuracy: 0.8793\n",
            "Epoch 52/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3374 - accuracy: 0.8832\n",
            "Epoch 53/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.3346 - accuracy: 0.8820\n",
            "Epoch 54/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.3388 - accuracy: 0.8818\n",
            "Epoch 55/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.3291 - accuracy: 0.8842\n",
            "Epoch 56/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.3332 - accuracy: 0.8832\n",
            "Epoch 57/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.3294 - accuracy: 0.8857\n",
            "Epoch 58/100\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.3204 - accuracy: 0.8898\n",
            "Epoch 59/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3226 - accuracy: 0.8876\n",
            "Epoch 60/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3224 - accuracy: 0.8874\n",
            "Epoch 61/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3139 - accuracy: 0.8904\n",
            "Epoch 62/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3165 - accuracy: 0.8876\n",
            "Epoch 63/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3096 - accuracy: 0.8938\n",
            "Epoch 64/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3072 - accuracy: 0.8930\n",
            "Epoch 65/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.2973 - accuracy: 0.8975\n",
            "Epoch 66/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.2970 - accuracy: 0.8965\n",
            "Epoch 67/100\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.3035 - accuracy: 0.8936\n",
            "Epoch 68/100\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.2942 - accuracy: 0.9006\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f639186d490>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "loss, acc = model.evaluate(test_iterator, steps=(len(test_iterator)//batch_size))\n",
        "print('Test loss:', loss)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMeaOwfrLyze",
        "outputId": "48fb37d3-701f-4cdb-e8b7-a58da940dbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2439 - accuracy: 0.9375\n",
            "Test loss: 0.24391716718673706\n",
            "Test Accuracy: 93.750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_bDD2j9Lyws",
        "outputId": "1f10bd46-f952-4663-a42b-bcd1ad7b7c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REFERENCES:**\n",
        "1. https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/\n",
        "2. https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
        "3. https://machinelearningmastery.com/check-point-deep-learning-models-keras/"
      ],
      "metadata": {
        "id": "olntS95CLzeQ"
      }
    }
  ]
}